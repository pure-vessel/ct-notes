\documentclass{article}
\input{Headers/header}
\input{Headers/formal}
\input{Headers/graphs}

\usepackage[outputdir=Output, cache=false]{minted}

\DeclareMathOperator{\inv}{inv}
\DeclareMathOperator{\res}{res}

\begin{document}
\section{Введение.}
Собственно, зачем это всё? У нас во всех наших системах (включая мобильные) есть множество ядер, и чтобы ваш код эффективно работал, необходимо уметь распределять его по всем этим ядрам.\\
К сожалению, в наше время закон Мура выполнен, но выполнен не так, как нам хотелось бы:
\begin{figure}[H]
    \label{fig:50-years-of-microprocessor-trend-data}
    \includegraphics[scale=0.33]{"Images/50 Years of Microprocessor Trend Data"}
\end{figure}
Количество транзисторов всё ещё экспоненциально растёт, но если раньше это осуществлялось расположением всё большего количества транзисторов в одном ядре (чтобы увеличить производительность этого самого одного ядра), то сейчас у нас просто становится больше ядер, а производительность одного ядра растёт очень медленно.\\
% https://github.com/karlrupp/microprocessor-trend-data
Раньше вообще было просто жить: ты написал программу, и через несколько лет она ускоряется вдвое, потому что железо работает быстрее. А сейчас бесплатные ленчи кончились, приходится самим писать код, который будет масштабироваться на множество ядер.\\
Казалось бы, ну напиши код как-нибудь, и с ростом количества ядер он будет ускоряться. Да вот тут проблема: не любое место кода может быть параллельным. И простая арифметика даёт нам очень грустные результаты: пусть мы можем распараллелить только долю $p$ нашего кода (а $1-p$ останется последовательным). Тогда если нам дали $n$ ядер, то количество раз, в которое наш код ускорится, равно
\[
\dfrac1{1-p+\dfrac pn}
\]
Это называется законом Амдала.\\
И отсюда следует, что если нам дали 16 ядер и мы имеем $60\%$ кода параллельно, то ускорится он всего в 2.3 раза. Более того, если устремить $n$ к бесконечности, мы получим максимальное ускорение кода $\displaystyle\dfrac 1{1-p}$. Например, если доля параллельного кода $95\%$, то он не сможет ускориться больше, чем в 20 раз. А если $99\%$, то в 100 раз, что тоже очень грустно, потому что в серверных системах ядер дохера и больше, и всего в 100 раз~--- очень грустно. Поэтому надо реально очень сильно параллелить код.\\
Виды параллелизма.
\begin{itemize}
    \item Instruction-level parallelism. Это когда вы имеете два действия, которые не связаны друг с другом, и они автоматически процессором параллелятся. Сюда и конвейеры со спекулятивным исполнением, и Superscalar, и VLIW, и векторизация даже. Про всё, кроме последнего, можно почитать в конспекте ассемблера. Именно за счёт всего этого и выполнялся экспоненциальный рост производительности одного процессора. А перестал он расти потому, что у этого всего есть предел.
    \item Собственно, многопроцессорные системы. Работает хорошо, но надо явно параллелить самому.
\end{itemize}
Многопроцессорные системы:
\begin{itemize}
    \item Simultaneous multiprocessing~--- есть несколько процессов и шина. Туда же simultaneous threading, в котором процессор один, и в нём потоки, который для вас выглядит ровно как SMP.
    \item На деле используется non-uniform memory access (NUMA). Для вас это всё ещё выглядит как SMP, но когда вы знаете вашу архитектуру, вы можете писать специальные алгоритмы.
\end{itemize}
Операционные системы:
\begin{itemize}
    \item Однозадачные.
    \item Пакетные задания (batch processing).
    \item Многозадачные / с разделением времени. Такие создают для программиста иллюзию, что его программа~--- единственная. Такая иллюзия достигается вытесняющей многозадачностью. Исторически до неё была кооперативная многозадачность, где программист вставлял в свой код специальные команды, чтобы отдать время другим процессам. Сейчас ОС с кооперативной многозадачностью нет, но как программисты мы всё ещё можем жить с кооперативной многозадачностью: у нас есть одно приложение, и там физика, анимация, куча другой фигни,~--- и чтобы это написать, мы пишем кооперативную многозадачность.
\end{itemize}
Процесс~--- это сущность ОС, которые независимы, и именно для процессов ОС делает иллюзию, что они одни.\\
Поток~--- контекст исполнения внутри процесса.\\
Но тут проблема: теория многопоточки сильно древнее, чем многопоточка. Поэтому в теории термином <<процесс>> называется то, что на самом деле поток.
\section{Формализм.}
Нужна формальная модель параллельных вычислений. Зачем? Чтобы доказывать корректность алгоритмов и и невозможность построения других алгоритмов. Но ещё он нужен, чтобы вы как программист понимали, что вам обещает разработчик языка, и что вы хотите от него.\\
Какие у нас модели бывают? Ну, у нас раньше были многочисленные однопоточные модели (RAM-модель, pointer-machine, машина тьюринга, куча другого мусора). Но у нас всё это одно и то же, у нас есть совершенно не важно, какие вычислители, нам важно лишь, как эти вычислители взаимодействуют.
\begin{itemize}
    \item Модель с общей памятью. Именно об этом мы и будем думать на этом курсе, потому что многоядерники в жизни так и работают. Да, на самом деле внутри каждого процесса передача сообщений, но для нас (программиста) нет ничего, кроме абстракции общей памяти.
    \item Модель с передачей сообщений. И это уже распределённые системы, потому что у них память у каждого своя.
\end{itemize}
Из интересного эти системы эквивалентны. Но они будут сильно отличаться по производительностью.\\
Возьмём чуть более конкретную модель вокруг общей памяти: у нас будут общие объекты, а не просто куски памяти. Простейший вариант общего объекта~--- общая переменная, в которую можно читать и писать. Это база, строительный блок для всего более сложного.\\
Тут опять же проблема с терминологией старых исследований. Общие переменные называются регистрами. Но нам, впрочем, регистры внутри процессора не нужны, так что путаницы не будет.\\
Тут мы имеем интересность. Если нам дана программа и входные данные, то результат будет всегда один и тот же. С многопоточкой не так, поэтому если мы хотим утверждать что-то про программу, то нам нужно проверить искомое свойство при любом исполнении.\\
Пример: пусть у нас есть два процесса (\Verb|P| и \Verb|Q|), у которых вот что:
\begin{verbatim}
shared int x = 0, y = 0;
    \end{verbatim}
\begin{multicols}{2}
\begin{verbatim}
    P:
1: x = 1
2: r1 = y
3: stop
\end{verbatim}
\columnbreak
\begin{verbatim}
    Q:
1: y = 1
2: r2 = x
3: stop
\end{verbatim}
\end{multicols}
Как можно посмотреть на исполнение этой программы? Ну, у нас есть начальное состояние (где \Verb|x| и \Verb|y| равны нулю), а потом у нас может выполниться либо шаг \Verb|P|, либо шаг \Verb|Q|.
\begin{figure}[H]
    \begin{tikzpicture}[
        level distance=2cm,
        level 1/.style={sibling distance=4cm},
        level 2/.style={sibling distance=4cm},
        level 3/.style={sibling distance=4cm},
        treenode/.style={
                inner sep=0pt,
                text width=12mm,
                scale=1,
                circle,
                outer sep=0mm,
                align=center,
                draw=black,
                fill=white,
                thin
        }
        ]
        \node[treenode] {$\substack{P:1,Q:1\\x,y=0,0\\r=0,0}$}
        child {
            node[treenode] {$\substack{P:2,Q:1\\x,y=1,0\\r=0,0}$}
            child {
                node[treenode] {$\substack{P:3,Q:1\\x,y=1,0\\r=0,0}$}
                child {
                    node[treenode] {$\substack{P:3,Q:2\\x,y=1,1\\r=0,0}$}
                    child {
                        node[treenode] {$\substack{P:3,Q:3\\x,y=1,1\\r=0,1}$}
                        edge from parent[->]
                        edge from parent node[left] {\Verb|r2 = x|}
                    }
                    edge from parent[->]
                    edge from parent node[left] {\Verb|y = 1|}
                }
                edge from parent[->]
                edge from parent node[left] {\Verb|r1 = y|}
            }
            child {
                node[treenode] (PQ) {$\substack{P:2,Q:2\\x,y=1,1\\r=0,0}$}
                child {
                    node[treenode] {$\substack{P:3,Q:2\\x,y=1,1\\r=1,0}$}
                    child {
                        edge from parent[draw=none]
                    }
                    child {
                        node[treenode] (P2Q2) {$\substack{P:3,Q:3\\x,y=1,1\\r=1,1}$}
                        edge from parent[->]
                        edge from parent node[left] {\Verb|r2 = x|}
                    }
                    edge from parent[->]
                    edge from parent node[left] {\Verb|r1 = y|}
                }
                child {
                    node[treenode] (PQ2) {$\substack{P:2,Q:3\\x,y=1,1\\r=0,1}$}
                    edge from parent[->]
                    edge from parent node[left] {\Verb|r2 = x|}
                }
                edge from parent[->]
                edge from parent node[right] {\Verb|y = 1|}
            }
            edge from parent[->]
            edge from parent node[left] {\Verb|x = 1|}
        }
        child {
            node[treenode] (Q) {$\substack{P:1,Q:2\\x,y=0,1\\r=0,0}$}
            child {
                (PQ)
                edge from parent[draw=none]
            }
            child {
                node[treenode] {$\substack{P:1,Q:3\\x,y=0,1\\r=0,0}$}
                child {
                    node[treenode] {$\substack{P:2,Q:3\\x,y=1,1\\r=0,0}$}
                    child {
                        node[treenode] {$\substack{P:3,Q:3\\x,y=1,1\\r=1,0}$}
                        edge from parent[->]
                        edge from parent node[left] {\Verb|r1 = y|}
                    }
                    edge from parent[->]
                    edge from parent node[left] {\Verb|x = 1|}
                }
                edge from parent[->]
                edge from parent node[right] {\Verb|r2 = x|}
            }
            edge from parent[->]
            edge from parent node[right] {\Verb|y = 1|}
        };
        \draw[->] (Q) -> node[right] {\Verb|x = 1|} (PQ);
        \draw[->] (PQ2) -> node[right] {\Verb|r1 = y|} (P2Q2);
    \end{tikzpicture}
\end{figure}\noindent
Получается, что у этой программы могут быть разные ответы. И у нас модель (модель чередования действий) очень проста, к тому же, а на практике вариантов сильно больше.\\
Насколько такая модель соотносится с реальностью? Ну, например, так?
\begin{minted}{java}
@JCStressTest
@State
@Outcome(id = "0, 1", expect = Expect.ACCEPTED)
@Outcome(id = "1, 1", expect = Expect.ACCEPTED)
@Outcome(id = "1, 0", expect = Expect.ACCEPTED)
public class SimpleTest1 {
    int x;
    int y;

    @Actor
    public void threadP(IntResult2 r) {
        x = 1;
        r.r1 = y;
    }

    @Actor
    public void threadQ(IntResult2 r) {
        y = 1;
        r.r2 = x;
    }
}
\end{minted}
Эта байда падает, потому что появляется вариант \mintinline{java}|"0, 0"|. Как, почему?\\
А потому что модель плоха. Вместо неё рассмотрим TSO, где каждая запись последовательно попадает в буфер памяти (у каждого потока свой), из которой потом когда-нибудь попадает в память. Отсюда и такой вариант. И это на x86, а если на ARM посмотреть, то там всё далеко от TSO, там хуже.\\
Но то про исполнение, а у нас же между ним и нами есть компилятор, и он может делать любую хрень, например, переставлять инструкции.\\
А ещё в модели чередования есть фундаментальная проблема: она последовательная. А в жизни операции чтения и записи не мгновенные, и происходят истинно параллельно. Даже без многопоточки, потому что конвейеры и Superscalar. А ещё свет за такт процессора с частотой 3ГГц проходит 10см (и это в вакууме), то есть синхронизироваться соседние процессоры на плате не успевают.\\
Собственно, СТО даёт нам терминологию: $a$ предшествует $b$, если свет из $a$ успевает дойти до $b$. И это частичный порядок, а не полный.\\
Из этого есть как раз терминология в виде <<произошло до>> (\textbf{happens before}). Исполнение системы~--- пара $H$ и $\to_H$, где $\to_H$~--- частичный (строгий) порядок (транзитивное, антирефлексивное, асимметричное отношение) на $H$, а $H$~--- множество чтений и записей общих объектов. $e\to_H f$ читается <<$e$ произошло до $f$>>. Ещё букву под стрелкой будем опускать, когда очевидно. Каждая операция будет состоять  из двух событий: $\inv e$~--- вызов операции и $\res e$~--- завершение $e$.\\
И тут важная деталь модели с общей памятью: события (не операции) строго упорядочены. Этот строгий порядок будет обозначаться знаком $<_H$. Эта иллюзия действительно поддерживается многоядерными системами. И тут, зная этот полный порядок, мы можем индуцировать отношение <<произошло до>> так: будем говорить, что $e$ случилось до $f$, если $\res e<_H\inv f$.\\
При этом все операции будем рисовать на графике глобального времени: есть какое-то глобальное время, и на нём расположены события. И на этой модели будут наглядно видны $\to$.\\
Система~--- набор всех возможных исполнений программы.\\
Кроме системы у нас есть какие-то гарантии. В спецификации у нас написано, что есть. Есть операции синхронизации (например, действие над \mintinline{c++}|std::atomic|) и, в более общем, модель памяти. Она описывает, что может произойти в многопоточной программе, а что~--- не может.\\
Пусть у нас произошло какое-то исполнение. Тогда мы можем описать его в терминах таких операций: \Verb|x.w(1)|~--- запись, и \Verb|x.r:1|~--- чтение и результат.\\
Исполнение называется \textbf{последовательным}, если все операции линейно упорядочены отношением <<произошло до>>.\\
Две операции над одной переменной, хотя бы одна из которых запись, называются \textbf{конфликтующими}. Конфликтующие операции не коммутируют в модели чередования.\\
Если две конфликтующие операции в данном исполнении произошло параллельно, такая ситуация называется \textbf{гонкой данных} (data race). Программа называется корректно синхронизированной, если в ней при любом исполнении нет гонок.\\
Сужение исполнения на поток $P$ ($H\big|_P$)~--- это исполнение, в котором остались только операции из $P$. Исполнение называется \textbf{правильным} (well-formed), если его сужение на каждый поток последовательно.\\
Программный порядок~--- это такой порядок: берём исполнение, сужаем на каждый поток, получаем порядок операций в нём, объединяем это для всех потоков.\\
\textbf{Сужение исполнения на объект}~--- множество всех операций, оперирующих с ним. Если сужение исполнения на объект является последовательным, то можно проверить его на соответствие \textbf{последовательной спецификации объекта} (т.е., по сути, контракту). Например, у регистра процессора последовательная спецификация в том, чтобы чтение возвращало результат последней записи.\\
Если в исполнении для любого объекта (для которого можно проверить) выполнена последовательная спецификация, исполнение называется \textbf{допустимым} (legal).\\
Но как определить допустимость параллельного исполнения? Тут так: каждому исполнению сопоставим допустимое последовательное исполнение. А как~--- вопрос. Всё это~--- условия согласованности. Их вагон, но среди них есть основное правило: корректные последовательные программы должны считаться согласованными при любом их исполнении в одном потоке.\\
Нас больше всего интересуют два условия согласованности:
\begin{itemize}
    \item Исполнение \textbf{последовательно согласовано}, если можно сопоставить эквивалентное ему допустимое последовательное исполнение, которое сохраняет \underline{программный порядок}. Беда: последовательная согласованность на каждом объекте не влечёт последовательной согласованности всего исполнения. Поэтому можно давать гарантии про всю систему (вся JVM последовательно согласована), а про отдельные объекты давать такую гарантию невозможно и групо.
    \item Исполнение \textbf{линеаризуемо}, если можно сопоставить эквивалентное ему допустимое последовательное исполнение, которое сохраняет \underline{весь порядок <<произошло до>>}. Такое последовательное исполнение называется \textbf{линеаризация}.
\end{itemize}
\begin{theorem}[Локальность линеаризуемости]
    Исполнение линеаризуемо тогда и только тогда, когда линеаризуемо исполнение на каждом объекте по отдельности.
\end{theorem}
\begin{proof}
    \mbox{}\\
    \begin{itemize}
        \item[Тогда.] Очевидно.
        \item[Только тогда.] Пусть $H$ линеаризуемо на каждом объекте $x$. Возьмем объединение:
        \begin{itemize}
            \item Линерации отношения <<произошло до>> на каждом объекте $\to_x$.
            \item Исходного отношения <<произошло до>> $\to_H$.
        \end{itemize}
        Транзитивно замкнем (сохранился исходный порядок и на объектах).\\
        Почему нет циклов? От противного.\\
        Поскольку $\to_H$ и $\to_x$ по отдельности транзитивны, наш цикл можно порезать так, чтобы одинаковых подряд не было.\\
        Ещё у нас не может быть $e\to_xf\to_yg$, потому что тогда $f$ должно делать что-то и с $x$, и с $y$, а такого у нас в модели нет.\\
        Значит в нашем цикле стрелки чередуются. Посмотрим $e\to_Hf\to_xg\to_Hh$. Это значит следующее:
        \begin{itemize}
            \item $\res e<\inv f$.
            \item $\inv f<\res g$, иначе было бы $g\to_Hf$, что противоречит $f\to_xg$.
            \item $\res g<\inv h$.
        \end{itemize}
        Отсюда $e\to_H g$, а значит цикл можно срезать ещё, и резать его, пока он не кончится. А цикл длины 2 некорректен.
    \end{itemize}
\end{proof}
\begin{remark}
    В распределённых системах нет линеаризуемости :(
\end{remark}
\begin{remark}
    А ещё в модели глобального времени можно рисовать точки линеаризации внутри операций. По сути это и есть линеаризуемость: внутри операции можно выделить момент, когда она возымела эффект.
\end{remark}
\begin{remark}
    Исполнение системы, выполняющей операции над линеаризуемыми объектами, можно анализировать в модели чередования.
\end{remark}
\begin{remark}
    Если нам дают простые линеаризуемые объекты, из них мы сможем построить более сложный линеаризуемый объект, доказать линеаризуемость и забыть о том, как мы этот объект сделали.
\end{remark}
\begin{definition}
    Говорят, что объект \textbf{потокобезопасен} (thread-safe), если он не линеаризуем (если не сказано иного).
\end{definition}
\begin{example}
    В JVM все операции над \mintinline{java}|volatile|-переменными операциями синхронизации (17.4.2), которые всегда линейно-упорядочены в любом исполнении (17.4.4) и согласованы с точки зрения чтения/записи (17.4.7) (следовательно, они линеаризуемы). Над не-\mintinline{java}|volatile|-полями операции могут быть даже не последовательно согласовано.
\end{example}
\begin{example}
    В JVM любая корректно синхронизированная программа последовательно согласована.
\end{example}
\begin{example}
    В C++ \mintinline{c++}|std::memory_order::seq_cst| в комбинации с \mintinline{c++}|std::atomic| даёт гарантию линеаризуемости.
\end{example}
Ну так лол, поправим наш код:
\begin{minted}{java}
    @JCStressTest
    @State
    @Outcome(id = "0, 1", expect = Expect.ACCEPTED)
    @Outcome(id = "1, 1", expect = Expect.ACCEPTED)
    @Outcome(id = "1, 0", expect = Expect.ACCEPTED)
    public class SimpleTest1 {
        volatile int x;
        volatile int y;
        
        @Actor
        public void threadP(IntResult2 r) {
            x = 1;
            r.r1 = y;
        }
        
        @Actor
        public void threadQ(IntResult2 r) {
            y = 1;
            r.r2 = x;
        }
    }
\end{minted}
А это байда уже работает. Почему? Потому что на самом деле теперь между операциями с \Verb|x| и \Verb|y| стоит инструкция \Verb|mfence|, которая сбрасывает буфер TSO.\\
Но проблема: \mintinline{java}|volatile| медленный, паскуда. Поэтому искуство многопоточки в том, чтобы расставить \mintinline{java}|volatile| только там, где надо, а где не надо~--- не расставить.
\end{document}
